{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and data\n",
    "\n",
    "Dataset was obtained in the capstone project description (direct link [here](https://d3c33hcgiwev3.cloudfront.net/_429455574e396743d399f3093a3cc23b_capstone.zip?Expires=1530403200&Signature=FECzbTVo6TH7aRh7dXXmrASucl~Cy5mlO94P7o0UXygd13S~Afi38FqCD7g9BOLsNExNB0go0aGkYPtodekxCGblpc3I~R8TCtWRrys~2gciwuJLGiRp4CfNtfp08sFvY9NENaRb6WE2H4jFsAo2Z2IbXV~llOJelI3k-9Waj~M_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A)) and splited manually in separated csv files. They were stored at my personal github account (folder link [here](https://github.com/caiomiyashiro/RecommenderSystemsNotebooks/tree/master/data/capstone)) and you can download and paste inside your working directory in order for this notebook to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "Float data came with ',' in the csv and python works with '.', so it treated the number as text. In order to convert them to numbers, I first replaced all the commas by punct and then converted the columns to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items.shape = (200, 7)\n",
      "actual_ratings.shape = (200, 100)\n",
      "content_based.shape = (200, 100)\n",
      "user_user.shape = (200, 100)\n",
      "item_item.shape = (200, 100)\n",
      "matrix_fact.shape = (200, 100)\n",
      "pers_bias.shape = (200, 100)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>75</th>\n",
       "      <th>79</th>\n",
       "      <th>83</th>\n",
       "      <th>112</th>\n",
       "      <th>252</th>\n",
       "      <th>271</th>\n",
       "      <th>301</th>\n",
       "      <th>305</th>\n",
       "      <th>...</th>\n",
       "      <th>3411</th>\n",
       "      <th>3430</th>\n",
       "      <th>3524</th>\n",
       "      <th>3533</th>\n",
       "      <th>3625</th>\n",
       "      <th>3902</th>\n",
       "      <th>3991</th>\n",
       "      <th>4047</th>\n",
       "      <th>4342</th>\n",
       "      <th>4462</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      64   65   75   79  83  112  252  271  301  305  ...   3411  3430  3524  \\\n",
       "item                                                  ...                      \n",
       "24   NaN  NaN  NaN  NaN NaN  NaN  4.0  5.0  4.0  5.0  ...    NaN   NaN   NaN   \n",
       "30   NaN  NaN  NaN  NaN NaN  NaN  NaN  NaN  NaN  NaN  ...    NaN   NaN   NaN   \n",
       "35   NaN  NaN  NaN  4.0 NaN  NaN  NaN  NaN  NaN  NaN  ...    NaN   NaN   NaN   \n",
       "41   NaN  NaN  NaN  NaN NaN  NaN  NaN  NaN  NaN  NaN  ...    NaN   NaN   NaN   \n",
       "45   NaN  5.0  4.0  5.0 NaN  NaN  NaN  NaN  NaN  5.0  ...    NaN   NaN   NaN   \n",
       "\n",
       "      3533  3625  3902  3991  4047  4342  4462  \n",
       "item                                            \n",
       "24     NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "30     NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "35     NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "41     NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "45     NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = pd.read_csv('data/capstone/Capstone Data - Office Products - Items.csv', index_col=0) \n",
    "actual_ratings = pd.read_csv('data/capstone/Capstone Data - Office Products - Ratings.csv', index_col=0) \n",
    "\n",
    "content_based = pd.read_csv('data/capstone/Capstone Data - Office Products - CBF.csv', index_col=0)\n",
    "user_user = pd.read_csv('data/capstone/Capstone Data - Office Products - User-User.csv', index_col=0)\n",
    "item_item = pd.read_csv('data/capstone/Capstone Data - Office Products - Item-Item.csv', index_col=0)\n",
    "matrix_fact = pd.read_csv('data/capstone/Capstone Data - Office Products - MF.csv', index_col=0)\n",
    "pers_bias = pd.read_csv('data/capstone/Capstone Data - Office Products - PersBias.csv', index_col=0)\n",
    "\n",
    "items[['Availability','Price']] = items[['Availability','Price']].apply(lambda col: col.apply(lambda elem: str(elem).replace(',', '.'))).astype(float)\n",
    "\n",
    "# preprocess\n",
    "content_based = content_based.apply(lambda col: col.apply(lambda elem: str(elem).replace(',', '.'))).astype(float)\n",
    "user_user = user_user.apply(lambda col: col.apply(lambda elem: str(elem).replace(',', '.'))).astype(float)\n",
    "item_item = item_item.apply(lambda col: col.apply(lambda elem: str(elem).replace(',', '.'))).astype(float)\n",
    "matrix_fact = matrix_fact.apply(lambda col: col.apply(lambda elem: str(elem).replace(',', '.'))).astype(float)\n",
    "pers_bias = pers_bias.apply(lambda col: col.apply(lambda elem: str(elem).replace(',', '.'))).astype(float)\n",
    "\n",
    "print('items.shape = ' + str(items.shape))\n",
    "print('actual_ratings.shape = ' + str(actual_ratings.shape))\n",
    "print('content_based.shape = ' + str(content_based.shape))\n",
    "print('user_user.shape = ' + str(user_user.shape))\n",
    "print('item_item.shape = ' + str(item_item.shape))\n",
    "print('matrix_fact.shape = ' + str(matrix_fact.shape))\n",
    "print('pers_bias.shape = ' + str(pers_bias.shape))\n",
    "\n",
    "actual_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class RecommenderEvaluator\n",
    "\n",
    "In order to become easier to evaluate the metrics, I created a class that receives all the original ratings and predicted ratings for every recommender system and defined functions to extract all the metrics established in section 1 of the capstone report. Lets take a look at a summary of the class before looking at the code:\n",
    "- **Constructor (init)**: receive all recommendation algorithms, besides the actual rating list and the list of items. All data is contained in the data downloaded from Coursera. Besides storing all recommendation algorithms, the constructor also calculate the 20 most frequent items, which is used in the popularity metric calculation.\n",
    "\n",
    "- **get_observed_ratings**: as the ratings matrix is sparse, this method only returns the items a user with id userId has purchased.\n",
    "\n",
    "- **get_top_n**: by ordering all the predicted ratings for each recommendation algorithm, we can extract what would be their 'top' recommendation for a given user. Given a parameter $n$, we can then return all the top $n$ recommendations for all the recommendation algorithms.\n",
    "\n",
    "- **rmse**: by comparing the observed ratings a given user has given to an item and the predicted rating an algorithm has defined for a user, we can have an idea of how much error the algorithm is predicting the user's ratings. Here we don't work with lists, as usually each user has rated only a few amount of items. So here we get all the items the user has rated, recover these items from the algorithms' recommendations and them calculate the error.\n",
    "\n",
    "- **nDCG**: By looking at lists now, we can have an idea of how optimal the ranked lists are. By using the scoring factor defined in the report, we can calculate the overall DCG for the recommenders' lists and then normalise them using the concepts of the nDCG.\n",
    "\n",
    "- **Price and avalaibility diversity**: Diversity metric which evaluate how the recommended items' prices vary, *i.e.*, how is the standard deviation of the price. The higher, the better in this case. The same is for the availability index, but here, with higher standard deviations, it means the models are recommending items which are present and not present in local stores.\n",
    "\n",
    "- **Popularity**: A popular recommender tries to recommend items which has a high chance of being purchased. In the formulation of this metric, an item has a high chance of being purchased if lots of people have purchased them. In the class constructor, we take the observed ratings data and the item list and select which were the top $n$ (standard = 20) most purchased data. In a recommendation list, we return the ration of how many items were inside this list of top $n$ ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class RecommenderEvaluator:\n",
    "    \n",
    "    def __init__(self, items, actual_ratings, content_based, user_user, item_item, matrix_fact, pers_bias):\n",
    "        \n",
    "        self.items = items\n",
    "        self.actual_ratings = actual_ratings\n",
    "        # static data containing the average score given by each user\n",
    "        self.average_rating_per_userid = actual_ratings.apply(lambda row: np.average(row[~np.isnan(row)]))\n",
    "        \n",
    "        self.content_based = content_based\n",
    "        self.user_user = user_user\n",
    "        self.item_item = item_item\n",
    "        self.matrix_fact = matrix_fact\n",
    "        self.pers_bias = pers_bias\n",
    "        \n",
    "        # aggregate list. Makes for loops among all recommenders' predictions easier\n",
    "        self.recommenders_list = [self.content_based, self.user_user, self.item_item, self.matrix_fact,self.pers_bias]\n",
    "        self.recommenders_list_names = ['content_based', 'user_user', 'item_item', 'matrix_fact','pers_bias']\n",
    "        \n",
    "        # Used for item popularity metric.\n",
    "        # Calculate the 20 most popular items (item which most of the customers bought)\n",
    "        N_LIM = 20\n",
    "        perc_users_bought_item = self.actual_ratings.apply(lambda item: np.sum(~np.isnan(item)), axis=0)/actual_ratings.shape[1]\n",
    "        sort_pop_items = np.argsort(perc_users_bought_item)[::-1]\n",
    "        self.pop_items = perc_users_bought_item.iloc[sort_pop_items][:N_LIM].index.values.astype(np.int)\n",
    "    \n",
    "        \n",
    "    def get_observed_ratings(self, userId):\n",
    "        \"\"\"\n",
    "        Returns all the items a given user evaluated and their ratings. Used mainly by all the metrics calculation\n",
    "        :parameter: userId - user id\n",
    "        :return: array of rated items. Index is the item id and value is the item rating\n",
    "        \"\"\"\n",
    "        userId = str(userId)\n",
    "        filtered_ratings = self.actual_ratings[userId]\n",
    "        rated_items = filtered_ratings[~np.isnan(filtered_ratings)]\n",
    "        return rated_items\n",
    "    \n",
    "    def get_top_n(self, userId, n):\n",
    "        \"\"\"\n",
    "        Get the top n recommendations for every recommender in the list given a user id\n",
    "        :parameter: userId - user id\n",
    "        :parameter: n - max number of recommendations to return\n",
    "        :return: dictionary where the key is the recommender's name and the value is an array of size n for the top n recommnendations.\n",
    "        \"\"\"\n",
    "        userId = str(userId)\n",
    "        predicted_ratings = dict()\n",
    "        for recommender, recommender_name in zip(self.recommenders_list,self.recommenders_list_names):\n",
    "            item_ids = recommender[userId].argsort().sort_values()[:n].index.values\n",
    "            predicted_ratings[recommender_name] = item_ids\n",
    "        return predicted_ratings\n",
    "    \n",
    "    def rmse(self, userId):\n",
    "        \"\"\"\n",
    "        Root Mean Square Error of the predicted and observed values between the recommender's prediction and the actual ratings\n",
    "        :parameter: userId - user id\n",
    "        :return: dataframe of containing the rmse from all recommenders given user id\n",
    "        \"\"\"\n",
    "        userId = str(userId)\n",
    "        observed_ratings = self.get_observed_ratings(userId)\n",
    "        rmse_list = {'rmse': []}\n",
    "        for recommender in self.recommenders_list:\n",
    "            predicted_ratings = recommender.loc[observed_ratings.index, userId]\n",
    "            rmse_list['rmse'].append(np.sqrt(np.average((predicted_ratings - observed_ratings)**2)))\n",
    "        rmse_list = pd.DataFrame(rmse_list, index = self.recommenders_list_names)\n",
    "        return rmse_list\n",
    "    \n",
    "    def nDCG(self, userId):\n",
    "        \"\"\"\n",
    "        Normalised Discounted Cumulative Gain for all recommenders given user id\n",
    "        :parameter: userId - user id\n",
    "        :return: dataframe of containing the nDCG from all recommenders given user id\n",
    "        \"\"\"\n",
    "        ri = self.get_observed_ratings(userId)\n",
    "        top5 = self.get_top_n(userId,5)\n",
    "\n",
    "        # 1st step: Given recommendations, transform list into scores (see score transcriptions in the capstone report)\n",
    "        scores_all = []\n",
    "        for name, item_list in top5.items():\n",
    "            scores = np.empty_like(item_list) # initialise 'random' array\n",
    "            scores[:] = -10                   ###########################\n",
    "                                                                   # check which items returned by the recommender\n",
    "            is_already_rated = np.isin(item_list, ri.index.values) # the user already rated. Items users didn't rate\n",
    "            scores[~is_already_rated] = 0                          # receive score = 0\n",
    "            for index, score in enumerate(scores):\n",
    "                if(score != 0):                                    # for each recommended items the user rated\n",
    "                    if(ri[item_list[index]] < self.average_rating_per_userid[userId] - 1): # score accordingly the report \n",
    "                        scores[index] = -1\n",
    "                    elif((ri[item_list[index]] >= self.average_rating_per_userid[userId] - 1) & \n",
    "                         (ri[item_list[index]] < self.average_rating_per_userid[userId] + 0.5)):\n",
    "                        scores[index] = 1\n",
    "                    else:\n",
    "                        scores[index] = 2\n",
    "            scores_all.append(scores)                              # append all the transformed scores\n",
    "        scores_all  \n",
    "\n",
    "        # 2nd step: Given scores, calculate the model's DCG, ideal DCG and then nDCG\n",
    "        nDCG_all = dict()\n",
    "        for index_model, scores_model in enumerate(scores_all):   # for each model\n",
    "            model_DCG = 0                                         # calculate model's DCG\n",
    "            for index, score in enumerate(scores_model):          #\n",
    "                index_ = index + 1                                #\n",
    "                model_DCG = model_DCG + score/np.log2(index_ + 1) #   \n",
    "            ideal_rank_items = np.sort(scores_model)[::-1]                        # calculate model's ideal DCG\n",
    "            ideal_rank_DCG = 0                                                    #\n",
    "            for index, ideal_score in enumerate(ideal_rank_items):                #\n",
    "                index_ = index + 1                                                #\n",
    "                ideal_rank_DCG = ideal_rank_DCG + ideal_score/np.log2(index_ + 1) #\n",
    "            if((ideal_rank_DCG == 0) | (np.abs(ideal_rank_DCG) < np.abs(model_DCG))): # if nDCG is 0 or only negative scores came up\n",
    "                nDCG = 0 \n",
    "            else:                                                     # calculate final nDCG when ideal DCG is != 0\n",
    "                nDCG = model_DCG/ideal_rank_DCG\n",
    "                                                         \n",
    "            nDCG_all[self.recommenders_list_names[index_model]] = nDCG # save each model's nDCG in a dict\n",
    "            # convert it to dataframe\n",
    "            result_final = pd.DataFrame(nDCG_all, index=range(1)).transpose()\n",
    "            result_final.columns = ['nDCG']\n",
    "        return result_final\n",
    "\n",
    "    def price_diversity(self,userId):\n",
    "        \"\"\"\n",
    "        Mean and standard deviation of the price of the top n products recommended by each algorithm. \n",
    "        Intuition for a high price wise diversity recommender is to have a high price standard deviation\n",
    "        :parameter: userId - user id\n",
    "        :return: dataframe of containing the price's mean and standard deviation from all recommenders given user id\n",
    "        \"\"\"\n",
    "\n",
    "        topn = self.get_top_n(userId,5)\n",
    "\n",
    "        stats = pd.DataFrame()\n",
    "        for key, value in topn.items():\n",
    "            data_filtered = self.items.loc[topn[key]][['Price']].agg(['mean','std']).transpose()\n",
    "            data_filtered.index = [key]\n",
    "            stats = stats.append(data_filtered)\n",
    "        return stats\n",
    "    \n",
    "    def availability_diversity(self,userId):\n",
    "        \"\"\"\n",
    "        Mean and standard deviation of the availabity index of the top n products recommended by each algorithm. \n",
    "        Intuition for a high availabity diversity is to have a small mean value in the availabity index\n",
    "        :parameter: userId - user id\n",
    "        :return: dataframe of containing the availabity index's mean and standard deviation from all recommenders given user id\n",
    "        \"\"\"\n",
    "        topn = self.get_top_n(userId,5)\n",
    "\n",
    "        stats = pd.DataFrame()\n",
    "        for key, value in topn.items():\n",
    "            data_filtered = self.items.loc[topn[key]][['Availability']].agg(['mean','std']).transpose()\n",
    "            data_filtered.index = [key]\n",
    "            stats = stats.append(data_filtered)\n",
    "        return stats\n",
    "    def popularity(self, userId):\n",
    "        \"\"\"\n",
    "        Return the ratio of how many items of the top n items are among the most popular purchased items. Default is\n",
    "        the 20 most purchased items.\n",
    "        :parameter: userId - user id\n",
    "        :return: dataframe of containing ratio of popular items in the recommended list from all recommenders given user id\n",
    "        \"\"\"\n",
    "        topn = self.get_top_n(userId,5)\n",
    "\n",
    "        recommended = re.get_top_n(userId,5)\n",
    "\n",
    "        results = {'popularity': []}\n",
    "        for recommender, recommendations in recommended.items():\n",
    "            popularity = np.sum(np.isin(recommendations,self.pop_items))\n",
    "            results['popularity'].append(popularity)\n",
    "        return pd.DataFrame(results,index = self.recommenders_list_names)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test methods:\n",
    "\n",
    "Just to have an idea of the output of each method, lets call all them with a test user. At the next section we will calculate these metrics for all users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "userId = '64'\n",
    "re = RecommenderEvaluator(items, actual_ratings, content_based, user_user, item_item, matrix_fact, pers_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>content_based</th>\n",
       "      <td>0.772809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_user</th>\n",
       "      <td>0.624086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_item</th>\n",
       "      <td>0.797922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matrix_fact</th>\n",
       "      <td>0.853212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pers_bias</th>\n",
       "      <td>0.845591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   rmse\n",
       "content_based  0.772809\n",
       "user_user      0.624086\n",
       "item_item      0.797922\n",
       "matrix_fact    0.853212\n",
       "pers_bias      0.845591"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.rmse(userId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test nDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nDCG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>content_based</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_item</th>\n",
       "      <td>0.63093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matrix_fact</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pers_bias</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_user</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  nDCG\n",
       "content_based  0.00000\n",
       "item_item      0.63093\n",
       "matrix_fact    0.00000\n",
       "pers_bias      0.00000\n",
       "user_user      0.00000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.nDCG(userId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Diversity - Price and Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>content_based</th>\n",
       "      <td>10.376</td>\n",
       "      <td>5.160923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_user</th>\n",
       "      <td>19.846</td>\n",
       "      <td>14.888584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_item</th>\n",
       "      <td>6.518</td>\n",
       "      <td>3.736117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matrix_fact</th>\n",
       "      <td>9.706</td>\n",
       "      <td>5.622004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pers_bias</th>\n",
       "      <td>9.890</td>\n",
       "      <td>5.121875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean        std\n",
       "content_based  10.376   5.160923\n",
       "user_user      19.846  14.888584\n",
       "item_item       6.518   3.736117\n",
       "matrix_fact     9.706   5.622004\n",
       "pers_bias       9.890   5.121875"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.price_diversity(userId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>content_based</th>\n",
       "      <td>0.595712</td>\n",
       "      <td>0.197574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_user</th>\n",
       "      <td>0.628495</td>\n",
       "      <td>0.124328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_item</th>\n",
       "      <td>0.531987</td>\n",
       "      <td>0.228363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matrix_fact</th>\n",
       "      <td>0.588537</td>\n",
       "      <td>0.197005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pers_bias</th>\n",
       "      <td>0.588596</td>\n",
       "      <td>0.172630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mean       std\n",
       "content_based  0.595712  0.197574\n",
       "user_user      0.628495  0.124328\n",
       "item_item      0.531987  0.228363\n",
       "matrix_fact    0.588537  0.197005\n",
       "pers_bias      0.588596  0.172630"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.availability_diversity(userId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>content_based</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_user</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_item</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>matrix_fact</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pers_bias</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               popularity\n",
       "content_based           0\n",
       "user_user               0\n",
       "item_item               0\n",
       "matrix_fact             0\n",
       "pers_bias               0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.popularity(userId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average metrics by all users\n",
    "\n",
    "Espefically for user 907, the recommendations from the user user came with all nulls (original dataset). This specifically impacted the RMSE calculation, as one Nan damaged the entire average calculation. So specifically for RMSE we did a separate calculation section. All the other metrics are going the be calculated in the next code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average RMSE for all users\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "content_based    0.572387\n",
       "user_user        0.545130\n",
       "item_item        0.574672\n",
       "matrix_fact      0.659029\n",
       "pers_bias        0.666273\n",
       "Name: rmse, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re = RecommenderEvaluator(items, actual_ratings, content_based, user_user, item_item, matrix_fact, pers_bias)\n",
    "\n",
    "i = 0\n",
    "count = np.array([0,0,0,0,0])\n",
    "for userId in actual_ratings.columns:\n",
    "    if(userId == '907'):\n",
    "        rmse_recommenders = re.rmse(userId).fillna(0)\n",
    "    else:\n",
    "        rmse_recommenders = re.rmse(userId)\n",
    "    count = count + rmse_recommenders['rmse']\n",
    "\n",
    "# as we didn't use user 907 for user user, divide it by the number of users - 1\n",
    "denominator = [len(actual_ratings.columns)] * 5\n",
    "denominator[1] = len(actual_ratings.columns) - 1\n",
    "print('Average RMSE for all users')\n",
    "count/ denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "Average nDCG\n",
      "---\n",
      "\n",
      "content_based    0.136505\n",
      "item_item        0.146798\n",
      "matrix_fact      0.155888\n",
      "pers_bias        0.125180\n",
      "user_user        0.169080\n",
      "Name: nDCG, dtype: float64\n",
      "\n",
      "---\n",
      "Average Price Diversity\n",
      "---\n",
      "\n",
      "                    mean        std\n",
      "content_based  19.240238  19.178071\n",
      "user_user      21.910497  25.222586\n",
      "item_item      25.880743  32.173458\n",
      "matrix_fact    21.119133  26.189485\n",
      "pers_bias       9.890000   5.121875\n",
      "\n",
      "---\n",
      "Average Availability Diversity\n",
      "---\n",
      "\n",
      "                   mean       std\n",
      "content_based  0.677648  0.227399\n",
      "user_user      0.831211  0.329105\n",
      "item_item      0.670905  0.211142\n",
      "matrix_fact    0.658213  0.208816\n",
      "pers_bias      0.687496  0.223849\n",
      "\n",
      "---\n",
      "Average Popularity\n",
      "---\n",
      "\n",
      "content_based    0.00\n",
      "user_user        0.04\n",
      "item_item        0.01\n",
      "matrix_fact      0.00\n",
      "pers_bias        0.00\n",
      "Name: popularity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "count_nDCG = np.array([0,0,0,0,0])\n",
    "count_diversity_price = np.ndarray([5,2])\n",
    "count_diversity_availability = np.ndarray([5,2])\n",
    "count_popularity = np.array([0,0,0,0,0])\n",
    "\n",
    "for userId in actual_ratings.columns:\n",
    "    nDCG_recommenders = re.nDCG(userId)\n",
    "    count_nDCG = count_nDCG + nDCG_recommenders['nDCG']\n",
    "    \n",
    "    diversity_price_recommenders = re.price_diversity(userId)\n",
    "    count_diversity_price = count_diversity_price + diversity_price_recommenders[['mean','std']]\n",
    "    \n",
    "    diversity_availability_recommenders = re.availability_diversity(userId)\n",
    "    count_diversity_availability = count_diversity_availability + diversity_availability_recommenders[['mean','std']]\n",
    "    \n",
    "    popularity_recommenders = re.popularity(userId)\n",
    "    count_popularity = count_popularity + popularity_recommenders['popularity'] \n",
    "    break\n",
    "\n",
    "print('\\n---')\n",
    "print('Average nDCG')\n",
    "print('---\\n')\n",
    "print(count_nDCG/len(actual_ratings.columns))\n",
    "print('\\n---')\n",
    "print('Average Price Diversity')\n",
    "print('---\\n')\n",
    "print(count_diversity_price/len(actual_ratings.columns))\n",
    "print('\\n---')\n",
    "print('Average Availability Diversity')\n",
    "print('---\\n')\n",
    "print(count_diversity_availability/len(actual_ratings.columns))\n",
    "print('\\n---')\n",
    "print('Average Popularity')\n",
    "print('---\\n')\n",
    "print(count_popularity/len(actual_ratings.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Analysis\n",
    "\n",
    "In terms of **RMSE**, the user-user collaborative filtering showed to be the most effective, despite it not being significantly better.\n",
    "\n",
    "For nDCG rank score, again user user and now item item collaborative filtering were the best.\n",
    "\n",
    "In terms of price diversity, the item item algorith was the most diverse, providing products varying ~32 dollars from the mean item price list. Matrix factorisation and user user follow right behind, with price standard deviation around 25 dollars. An interesting factor here was the *pers_bias* algorithm, as it recommended basically cheap products with a low standard deviation.\n",
    "\n",
    "For the availabity index, all the algorithms besides the user user managed to recommend items not so present in the local stores **together** with items present in local stores, as we can see they also provided items with availability index high (high standard deviation).\n",
    "\n",
    "In terms of popularity, no algorithm actually managed to obtain good scores in the way we defined. So, if the popularity is focused in the future, we can either change the popularity concept or improve mechanics in the recommender so it predict higher scores for the most popular items in the store.\n",
    "\n",
    "After this evaluation, it seemed to us that the item-item recommender system had an overall better performance, highlighted in terms of its diversity scores. Unfortunately, the items that item item recommender has suggested are in overall pricy, and we can check if there is any mixture possibility with the pers_bias algorithm, as it really indicated cheap prices and a low price standard deviation. Matrix factorization performed good as well but it didn't outperform any of the other recommenders."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
